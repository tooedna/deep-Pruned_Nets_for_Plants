{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda1,floatX=float32, nvcc.flags=-D_FORCE_INLINES\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "import os.path\n",
    "\n",
    "import densenet\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D,SeparableConv2D\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "from inner_func import get_hubs_last_conv_name, get_filtered_idx, get_last_conv_layer_name, recursive_find_root_conv\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "batch_size = 100\n",
    "nb_classes = 38\n",
    "nb_epoch = 300\n",
    "\n",
    "img_rows, img_cols = 224, 224\n",
    "img_channels = 3\n",
    "\n",
    "img_dim = (img_rows, img_cols, img_channels) \n",
    "nb_classes=38\n",
    "depth = 169\n",
    "nb_dense_block = 4\n",
    "nb_layers_per_block=[6, 12, 32, 32]\n",
    "growth_rate = 32\n",
    "nb_filter = 64\n",
    "\n",
    "dropout_rate = 0.5 # 0.0 for data augmentation\n",
    "root_total = '/media/data/TOO/DATASETS/PlantVillage/PlantVillage/train/'\n",
    "disease_CLASSES = listdir(root_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "#from keras.utils import plot_model\n",
    "batch_size = 48\n",
    "nb_epoch = 30\n",
    "\n",
    "    # Load our model\n",
    "#model = TELU_DEPTH.DenseNetImageNet121(img_dim, classes=nb_classes, reduction=0.5, \n",
    "#                           dropout_rate=dropout_rate, bottleneck=True,weights=None)\n",
    "model=densenet.DenseNet(img_dim, depth=depth, nb_dense_block=nb_dense_block, growth_rate=growth_rate, nb_filter=nb_filter,\n",
    "                    nb_layers_per_block=nb_layers_per_block, bottleneck=True, reduction=0.5,\n",
    "                    dropout_rate=dropout_rate, subsample_initial_block=True,\n",
    "                     weights=None, \n",
    "                    classes=nb_classes, activation='softmax')\n",
    "\n",
    "print(\"Model created\")\n",
    "# Load model\n",
    "weights_file='/media/data/TOO/plantsdiseases/imagenet_models/densenet169_weights_tf.h5'\n",
    "\n",
    "model.load_weights(weights_file, by_name=True)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_rows, img_cols), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    \n",
    "    for fld in disease_CLASSES:\n",
    "        index = disease_CLASSES.index(fld)\n",
    "        \n",
    "        path = os.path.join('..', 'DATASETS', 'train', fld,'*')\n",
    "        files = glob.glob(path)\n",
    "        #print path\n",
    "        #print files\n",
    "        for fl in files:\n",
    "            #print str(fl)\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2(fl)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id\n",
    "\n",
    "train_data, train_target, train_id = load_train()\n",
    "\n",
    "train_data=np.array(train_data, dtype=np.uint8)\n",
    "\n",
    "train_data=(train_data.astype('float32'))/255\n",
    "\n",
    "#mean and std deviation of training set\n",
    "data_mean=np.mean(train_data,axis=0)\n",
    "data_stddev=np.std(train_data,axis=0)\n",
    "\n",
    "#normalize data according to mean and sdev of training set\n",
    "train_data=(train_data-data_mean)/data_stddev\n",
    "\n",
    "#Reshaping the dataset\n",
    "train_data=train_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "train_target = np_utils.to_categorical(train_target, nb_classes)\n",
    "\n",
    "print('train_data shape:', train_data.shape)\n",
    "print(train_data.shape[0], 'train samples')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val, Y_train,Y_val=train_test_split(train_data,train_target,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy','top_k_categorical_accuracy'])\n",
    "hist=model.fit(x_train, Y_train,\n",
    "              batch_size=48,\n",
    "              epochs=100,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(x_val,Y_val),\n",
    "              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc']); plt.plot(hist.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('Accuracy');\n",
    "plt.xlabel('Epoch'); plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left');\n",
    "# summarize history for Top_5_accuracy\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['top_k_categorical_accuracy']); plt.plot(hist.history['val_top_k_categorical_accuracy']);\n",
    "plt.title('model Top_5 Accuracy'); plt.ylabel('Accuracy');\n",
    "plt.xlabel('Epoch'); plt.legend(['Top_5 Training Accuracy', 'Top_5 Validation Accuracy'], loc='upper left');\n",
    "# summarize history for loss\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('Loss');\n",
    "plt.xlabel('Epoch'); plt.legend(['Training Loss', 'Validation Loss'], loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_rows, img_cols), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "def load_test():\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    y_test = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read TEST images')\n",
    "    #diseaseNames =  ['0']\n",
    "  \n",
    "    for fld in disease_CLASSES:\n",
    "        index = disease_CLASSES.index(fld)\n",
    "        \n",
    "        path = os.path.join('..', 'DATASETS', 'test', fld,'*')\n",
    "        \n",
    "        files = glob.glob(path)\n",
    "        #print (path)\n",
    "        #print (files)\n",
    "        for fl in files:\n",
    "            #print str(fl)\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2(fl)\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(flbase)\n",
    "            y_test.append(index)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, y_test, X_test_id\n",
    "test_data, test_target,test_id = load_test()\n",
    "X_test = np.array(test_data, dtype=np.uint8)\n",
    "#mean and std deviation of training set\n",
    "X_test = (X_test.astype('float32'))/255\n",
    "test_mean=np.mean(X_test,axis=0)\n",
    "test_stddev=np.std(X_test,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#normalize data according to mean and sdev of training set\n",
    "\n",
    "X_test=(X_test-test_mean)/test_stddev\n",
    "\n",
    "X_test = X_test.transpose((0, 1, 2, 3))\n",
    "\n",
    "# Normalizing the data\n",
    "\n",
    "#X_test /= 255\n",
    "y_test = np_utils.to_categorical(test_target, nb_classes)\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score=model.evaluate(X_test,y_test,verbose=1)\n",
    "\n",
    "print('Test Loss:',score[0])\n",
    "print('Test Accuracy:',score[1]*100)\n",
    "print ('Top_5 Accuracy',score[2]*100)\n",
    "print('Top_5 Error',100-score[2]*100)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
